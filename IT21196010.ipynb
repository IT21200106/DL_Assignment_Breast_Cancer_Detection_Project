{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q breast-histopathology-images.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from glob import glob\n",
    "from os import listdir\n",
    "\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "random.seed(98)\n",
    "np.random.seed(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = glob('dataset/IDC_regular_ps50_idx5/**/*.png', recursive= True)\n",
    "\n",
    "samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDC_negative = []\n",
    "IDC_positive = []\n",
    "\n",
    "for img in samples:\n",
    "  if img[-5] == '0':\n",
    "    IDC_negative.append(img)\n",
    "  else:\n",
    "    IDC_positive.append(img)\n",
    "\n",
    "print('Negative samples: ', IDC_negative[:3])\n",
    "print('Positive samples: ', IDC_positive[:3])\n",
    "print('Negative sample size: ', len(IDC_negative))\n",
    "print('Positive sample size: ', len(IDC_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a few IDC negative and positive samples for display\n",
    "sample_size = 6  # You can change this to the number of samples you want to display\n",
    "random_negative_samples = random.sample(IDC_negative, sample_size)\n",
    "random_positive_samples = random.sample(IDC_positive, sample_size)\n",
    "\n",
    "# Create subplots for IDC negative patches\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(sample_size):\n",
    "    plt.subplot(2, sample_size, i + 1)\n",
    "    img = mpimg.imread(random_negative_samples[i])\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('IDC Negative')\n",
    "\n",
    "# Create subplots for IDC positive patches\n",
    "for i in range(sample_size):\n",
    "    plt.subplot(2, sample_size, i + sample_size + 1)\n",
    "    img = mpimg.imread(random_positive_samples[i])\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('IDC Positive')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the image size\n",
    "IMG_SIZE = (96, 96)\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "# Define the number of samples to use from each class\n",
    "NUM_SAMPLES_PER_CLASS = 5000\n",
    "\n",
    "# Define lists to store features (X) and labels (y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Define a function to extract features and labels\n",
    "def extract_features_labels(sample_paths, label_value):\n",
    "    count = 0\n",
    "    for path in sample_paths:\n",
    "        if count >= NUM_SAMPLES_PER_CLASS:\n",
    "            break\n",
    "        img = Image.open(path).resize(IMG_SIZE, Image.LANCZOS)\n",
    "        X.append(np.array(img) / 255.0)\n",
    "        y.append(label_value)\n",
    "        count += 1\n",
    "\n",
    "# Extract features and labels for IDC negative samples (up to 20,000)\n",
    "extract_features_labels(IDC_negative, label_value=0)\n",
    "\n",
    "# Extract features and labels for IDC positive samples (up to 20,000)\n",
    "extract_features_labels(IDC_positive, label_value=1)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled_indices = np.arange(len(y))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "X = X[shuffled_indices]\n",
    "y = y[shuffled_indices]\n",
    "\n",
    "# Check the shape of the features and labels arrays\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split the data into train, test, and predict sets\n",
    "X_train, X_predict, y_train, y_true = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Define the ratio for reducing the size of the train and test sets\n",
    "rate = 0.5\n",
    "num = int(X.shape[0] * rate)\n",
    "\n",
    "# Reduce the size of the train and test sets\n",
    "X_test = X_train[num:]\n",
    "X_train = X_train[:num]\n",
    "\n",
    "y_test = y_train[num:]\n",
    "y_train = y_train[:num]\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "y_true = to_categorical(y_true, 2)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('X_predict shape: {}'.format(X_predict.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))\n",
    "print('y_true shape: {}'.format(y_true.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)  # Exclude the top fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model with custom classification layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "# Create a Sequential model for your custom classification task\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "Adam = Adam(learning_rate = 0.0001)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',   # Metric to monitor (e.g., validation loss)\n",
    "    patience=5,           # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,            # Verbosity mode (0: quiet, 1: update messages)\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 30, batch_size = 32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
